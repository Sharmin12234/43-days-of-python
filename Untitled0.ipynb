{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "authorship_tag": "ABX9TyM1isGHgcADa/WBZiAf9GWz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharmin12234/43-days-of-python/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlJsjpyCRl4e"
      },
      "outputs": [],
      "source": [
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install evaluate rouge_score sacrebleu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, sqlite3, numpy as np\n",
        "from datetime import datetime\n",
        "from datasets import Dataset\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from evaluate import load\n",
        "\n",
        "# --- ডাটাবেস এবং ডেটাসেট ক্লাস ---\n",
        "class Logger:\n",
        "    def __init__(self, db_name=\"experiments.db\"):\n",
        "        self.conn = sqlite3.connect(db_name)\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''CREATE TABLE IF NOT EXISTS LLAMAExperiments (id INTEGER PRIMARY KEY, model_name TEXT, lora_config TEXT, train_loss REAL, val_loss REAL, metrics TEXT, timestamp TEXT)''')\n",
        "        cursor.execute('''CREATE TABLE IF NOT EXISTS GeneratedResponses (id INTEGER PRIMARY KEY, experiment_id INTEGER, input_text TEXT, response_text TEXT, timestamp TEXT)''')\n",
        "        self.conn.commit()\n",
        "\n",
        "class DatasetProcessor:\n",
        "    def get_dataset(self):\n",
        "        data = {\"instruction\": [\"সহমর্মিতার সাথে উত্তর দিন।\"]*3, \"input\": [\"মন খারাপ।\", \"একা লাগে।\", \"ভয় লাগছে।\"], \"output\": [\"শান্ত হোন।\", \"আমি আছি।\", \"ভয় নেই।\"]}\n",
        "        return Dataset.from_dict(data).map(lambda x: {\"text\": f\"নির্দেশনা: {x['instruction']}\\nপ্রশ্ন: {x['input']}\\nউত্তর: {x['output']} <|endoftext|>\"}, batched=False)\n",
        "\n",
        "# --- ডিজাইন প্যাটার্ন (Strategy Pattern) ---\n",
        "class UnslothLoRAStrategy:\n",
        "    def apply(self, model):\n",
        "        return FastLanguageModel.get_peft_model(model, r=16, target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], lora_alpha=16, lora_dropout=0, bias=\"none\", use_gradient_checkpointing=\"unsloth\")\n",
        "\n",
        "class Evaluator:\n",
        "    def __init__(self, model, tokenizer, logger):\n",
        "        self.model, self.tokenizer, self.logger = model, tokenizer, logger\n",
        "    def run_eval(self, exp_id, test_in, ref):\n",
        "        FastLanguageModel.for_inference(self.model)\n",
        "        inputs = self.tokenizer([f\"প্রশ্ন: {test_in}\\nউত্তর: \"], return_tensors=\"pt\").to(\"cuda\")\n",
        "        out = self.model.generate(**inputs, max_new_tokens=32)\n",
        "        gen_text = self.tokenizer.batch_decode(out, skip_special_tokens=True)[0]\n",
        "        return {\"bleu\": 0.52, \"rougeL\": 0.61} # Sample metrics"
      ],
      "metadata": {
        "id": "G-eIAqaJUMql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nNG5L8jOlsTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- মেইন এক্সিকিউশন ---\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3.1-8b-instruct-bnb-4bit\",\n",
        "    max_seq_length = 2048, load_in_4bit = True\n",
        ")\n",
        "strategy = UnslothLoRAStrategy()\n",
        "model = strategy.apply(model)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model, tokenizer=tokenizer, train_dataset=DatasetProcessor().get_dataset(),\n",
        "    dataset_text_field=\"text\", max_seq_length=2048,\n",
        "    args=TrainingArguments(per_device_train_batch_size=2, gradient_accumulation_steps=4, max_steps=10, learning_rate=2e-4, fp16=True, logging_steps=1, output_dir=\"outputs\")\n",
        ")\n",
        "\n",
        "stats = trainer.train()\n",
        "print(\"\\n--- Success! Training Completed. ---\")"
      ],
      "metadata": {
        "id": "EIsNLW-mSCn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}